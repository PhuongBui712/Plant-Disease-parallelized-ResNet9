{"cells":[{"cell_type":"markdown","metadata":{},"source":["## Import libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-07-09T17:46:11.727576Z","iopub.status.busy":"2024-07-09T17:46:11.726893Z","iopub.status.idle":"2024-07-09T17:46:15.093609Z","shell.execute_reply":"2024-07-09T17:46:15.092625Z","shell.execute_reply.started":"2024-07-09T17:46:11.727542Z"},"trusted":true},"outputs":[],"source":["import math\n","import numpy as np\n","from tqdm import tqdm\n","from numba import cuda, float32\n","from typing import Optional, Callable, Tuple\n","\n","import torch\n","from torch import Tensor\n","from torch import nn\n","from torch.nn import functional as F\n","from torch import optim\n","\n","from torch.utils.data import Dataset, DataLoader, Subset\n","from torchvision.datasets import ImageFolder\n","from torchvision import transforms"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T17:46:15.096514Z","iopub.status.busy":"2024-07-09T17:46:15.095976Z","iopub.status.idle":"2024-07-09T17:46:15.100404Z","shell.execute_reply":"2024-07-09T17:46:15.099550Z","shell.execute_reply.started":"2024-07-09T17:46:15.096477Z"},"trusted":true},"outputs":[],"source":["device = torch.device('cuda:0')"]},{"cell_type":"markdown","metadata":{},"source":["## Numba ResNet9"]},{"cell_type":"markdown","metadata":{},"source":["### Conv2d"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T17:46:15.102719Z","iopub.status.busy":"2024-07-09T17:46:15.102078Z","iopub.status.idle":"2024-07-09T17:46:15.126188Z","shell.execute_reply":"2024-07-09T17:46:15.125097Z","shell.execute_reply.started":"2024-07-09T17:46:15.102667Z"},"trusted":true},"outputs":[],"source":["@cuda.jit\n","def conv2d_kernel(input: cuda.devicearray.DeviceNDArray,\n","                  kernel: cuda.devicearray.DeviceNDArray,\n","                  output: cuda.devicearray.DeviceNDArray,\n","                  padding: int,\n","                  stride: int):\n","    \"\"\"\n","    Performs a 2D convolution operation on a 4D tensor.\n","\n","    Args:\n","        input (cuda.devicearray.DeviceNDArray): The input tensor.\n","        kernel (cuda.devicearray.DeviceNDArray): The convolution kernel.\n","        output (cuda.devicearray.DeviceNDArray): The output tensor.\n","        padding (int): The amount of padding to apply.\n","        stride (int): The stride of the convolution operation.\n","    \"\"\"\n","    combined_idx, out_y, out_x = cuda.grid(3)\n","    batch_size, in_channels, in_height, in_width = input.shape\n","    out_channels, _, kernel_height, kernel_width = kernel.shape\n","    out_height, out_width = output.shape[2:]\n","\n","    batch_idx = combined_idx // out_channels\n","    out_channel_idx = combined_idx % out_channels\n","\n","    if batch_idx < batch_size and out_channel_idx < out_channels and out_y < out_height and out_x < out_width:\n","        res = 0.0\n","        for in_channel in range(in_channels):\n","            for ky in range(kernel_height):\n","                for kx in range(kernel_width):\n","                    in_y = out_y * stride - padding + ky\n","                    in_x = out_x * stride - padding + kx\n","                    if 0 <= in_y < in_height and 0 <= in_x < in_width:\n","                        res += input[batch_idx, in_channel, in_y, in_x] * kernel[out_channel_idx, in_channel, ky, kx]\n","        output[batch_idx, out_channel_idx, out_y, out_x] = res\n","\n","\n","class NumbaConv2d(torch.nn.Module):\n","    \"\"\"\n","    Performs a 2D convolution operation on a 4D tensor using Numba CUDA.\n","\n","    This class implements a convolution operation with configurable input and output channels, kernel size, padding, and stride.\n","    It leverages Numba CUDA for efficient GPU acceleration.\n","\n","    Args:\n","        in_channels (int): The number of input channels.\n","        out_channels (int): The number of output channels.\n","        kernel_size (int): The size of the convolution kernel.\n","        padding (Optional[int], optional): The amount of padding to apply. Defaults to 0.\n","        stride (Optional[int], optional): The stride of the convolution operation. Defaults to 1.\n","        weight (Optional[torch.Tensor], optional): The initial weight tensor. Defaults to None.\n","        bias (Optional[torch.Tensor], optional): The initial bias tensor. Defaults to None.\n","\n","    Example:\n","        >>> conv = NumbaConv2D(in_channels=3, out_channels=64, kernel_size=3, padding=1, stride=2)\n","        >>> input_tensor = torch.randn(16, 3, 512, 512, device='cuda')\n","        >>> output_tensor = conv(input_tensor)\n","    \"\"\"\n","    def __init__(self, in_channels, out_channels, kernel_size, padding=0, stride=1, weight=None, bias=None):\n","        super().__init__()\n","\n","        self.kernel = weight\n","        if self.kernel is None:\n","            self.kernel = nn.Parameter(torch.randn(out_channels, in_channels, kernel_size, kernel_size, device='cuda'))\n","\n","        self.bias = bias\n","        if self.bias is None:\n","            self.bias = nn.Parameter(torch.zeros(out_channels, device='cuda'))\n","\n","        self.padding = padding\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        assert x.is_cuda, \"Input must be a CUDA tensor\"\n","        assert x.dim() == 4, \"Input must be a 4D tensor\"\n","\n","        # Ensure input and kernel are in the same precision\n","        detached_x = x.detach()\n","        detached_kernel = self.kernel.detach()\n","\n","        batch_size, in_channels, in_height, in_width = x.shape\n","        out_channels, _, kernel_height, kernel_width = self.kernel.shape\n","        out_height = (in_height + 2 * self.padding - kernel_height) // self.stride + 1\n","        out_width = (in_width + 2 * self.padding - kernel_width) // self.stride + 1\n","\n","        output = torch.zeros(batch_size, out_channels, out_height, out_width,\n","                             dtype=torch.float32, device=x.device)\n","\n","        threads_per_block = (8, 8, 8)\n","        blocks_per_grid = (\n","            (batch_size * out_channels + threads_per_block[0] - 1) // threads_per_block[0],\n","            (out_height + threads_per_block[1] - 1) // threads_per_block[1],\n","            (out_width + threads_per_block[2] - 1) // threads_per_block[2]\n","        )\n","\n","        conv2d_kernel[blocks_per_grid, threads_per_block](\n","            detached_x, detached_kernel, output, self.padding, self.stride\n","        )\n","\n","        return output + self.bias.view(1, -1, 1, 1)\n"]},{"cell_type":"markdown","metadata":{},"source":["### MaxPool2d"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T17:46:15.127859Z","iopub.status.busy":"2024-07-09T17:46:15.127551Z","iopub.status.idle":"2024-07-09T17:46:15.142615Z","shell.execute_reply":"2024-07-09T17:46:15.141611Z","shell.execute_reply.started":"2024-07-09T17:46:15.127833Z"},"trusted":true},"outputs":[],"source":["MIN_FLOAT32 = torch.finfo(torch.float32).min\n","\n","@cuda.jit\n","def max_pool_2d_kernel(input: cuda.devicearray.DeviceNDArray,\n","                       output: cuda.devicearray.DeviceNDArray,\n","                       kernel_size: int,\n","                       padding: int,\n","                       stride: int):\n","    \"\"\"\n","    Performs a 2D max pooling operation on a 4D tensor.\n","\n","    Args:\n","        input (cuda.devicearray.DeviceNDArray): The input tensor.\n","        output (cuda.devicearray.DeviceNDArray): The output tensor.\n","        kernel_size (int): The size of the pooling kernel.\n","        padding (int): The amount of padding to apply.\n","        stride (int): The stride of the pooling operation.\n","    \"\"\"\n","    idx, out_h, out_w = cuda.grid(3)\n","    \n","    batch_idx = idx // input.shape[1]\n","    channel = idx % input.shape[1]\n","    \n","    if batch_idx < input.shape[0] and channel < input.shape[1] and out_h < input.shape[2] and out_w < input.shape[3]:\n","        for ky in range(kernel_size):\n","            for kx in range(kernel_size):\n","                in_y = out_h * stride - padding + ky\n","                in_x = out_w * stride - padding +kx\n","\n","                if 0 <= in_y < input.shape[2] and 0 <= in_x < input.shape[3]:\n","                    output[batch_idx, channel, out_h, out_w] = max(output[batch_idx, channel, out_h, out_w],\n","                                                                   input[batch_idx, channel, in_y, in_x])\n","\n","\n","class NumbaMaxPool2d(nn.Module):\n","    \"\"\"\n","    Performs a 2D max pooling operation on a 4D tensor using Numba CUDA.\n","\n","    This class implements a max pooling operation with configurable kernel size, padding, and stride.\n","    It leverages Numba CUDA for efficient GPU acceleration.\n","\n","    Args:\n","        kernel_size (int): The size of the pooling kernel.\n","        padding (Optional[int], optional): The amount of padding to apply. Defaults to 0.\n","        stride (Optional[int], optional): The stride of the pooling operation. Defaults to 1.\n","\n","    Example:\n","        >>> pool = NumbaMaxPool2d(kernel_size=2, padding=1, stride=2)\n","        >>> input_tensor = torch.randn(16, 3, 512, 512, device='cuda')\n","        >>> output_tensor = pool(input_tensor)\n","    \"\"\"\n","    def __init__(self,\n","                 kernel_size: int,\n","                 padding: Optional[int] = 0,\n","                 stride: Optional[int] = 1):\n","        super().__init__()\n","\n","        self.kernel_size = kernel_size\n","        self.padding = padding\n","        self.stride = stride or kernel_size\n","\n","    def forward(self, x):\n","        assert x.is_cuda, \"Input must be a CUDA tensor\"\n","        assert x.dim() == 4, \"Input must be a 4D tensor\"\n","\n","        detached_x = x.detach()\n","\n","        batch_size, channels, in_height, in_width = x.shape\n","        out_height = (in_height + 2 * self.padding - (self.kernel_size - 1) - 1) // self.stride + 1\n","        out_width = (in_width + 2 * self.padding - (self.kernel_size - 1) - 1) // self.stride + 1\n","\n","        output = torch.full(\n","            size=(batch_size, channels, out_height, out_width),\n","            fill_value=MIN_FLOAT32,\n","            device=x.device\n","        )\n","        \n","        threads_per_block = (8, 8, 8)\n","        blocks_per_grid = (\n","            math.ceil(batch_size * channels / threads_per_block[0]),\n","            math.ceil(out_height / threads_per_block[1]),\n","            math.ceil(out_width / threads_per_block[2])\n","        )\n","\n","        max_pool_2d_kernel[blocks_per_grid, threads_per_block](\n","            detached_x, output, self.kernel_size, self.padding, self.stride\n","        )\n","\n","        return output\n","    \n","\n","@cuda.jit\n","def _maxpool2d_kernel_2(input, output, kernel_size, stride, in_height, in_width, out_height, out_width, min_val):\n","    # Calculate indices\n","    idx = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n","    idy = cuda.threadIdx.y + cuda.blockIdx.y * cuda.blockDim.y\n","    idz = cuda.threadIdx.z + cuda.blockIdx.z * cuda.blockDim.z\n","\n","    # Map to 4D indices\n","    batch = idx // input.shape[1]\n","    channel = idx % input.shape[1]\n","    x = idy\n","    y = idz\n","\n","    if batch < input.shape[0] and channel < input.shape[1] and x < out_height and y < out_width:\n","        max_val = min_val\n","        for i in range(kernel_size):\n","            for j in range(kernel_size):\n","                in_x = x * stride + i\n","                in_y = y * stride + j\n","                if in_x < in_height and in_y < in_width:\n","                    val = input[batch, channel, in_x, in_y]\n","                    if val > max_val:\n","                        max_val = val\n","        output[batch, channel, x, y] = max_val\n","\n","class NumbaMaxPool2d_2(torch.nn.Module):\n","    def __init__(self, kernel_size, stride=None):\n","        super(NumbaMaxPool2d, self).__init__()\n","        self.kernel_size = kernel_size\n","        self.stride = stride if stride is not None else kernel_size\n","\n","    def forward(self, x):\n","        if not x.is_cuda:\n","            x = x.cuda()\n","        \n","        # Ensure input is float32\n","        x = x.float()\n","        \n","        input_shape = x.shape\n","        output_shape = (\n","            input_shape[0],  # batch size\n","            input_shape[1],  # channels\n","            (input_shape[2] - self.kernel_size) // self.stride + 1,  # height\n","            (input_shape[3] - self.kernel_size) // self.stride + 1   # width\n","        )\n","        \n","        output = torch.cuda.FloatTensor(*output_shape).fill_(MIN_FLOAT32)\n","        \n","        threads_per_block = (64, 64, 64)\n","        blocks_per_grid = (\n","            (input_shape[0] * input_shape[1] + threads_per_block[0] - 1) // threads_per_block[0],\n","            (output_shape[2] + threads_per_block[1] - 1) // threads_per_block[1],\n","            (output_shape[3] + threads_per_block[2] - 1) // threads_per_block[2]\n","        )\n","        \n","        _maxpool2d_kernel_2[blocks_per_grid, threads_per_block](\n","            x,\n","            output,\n","            self.kernel_size,\n","            self.stride,\n","            input_shape[2],  # in_height\n","            input_shape[3],  # in_width\n","            output_shape[2],  # out_height\n","            output_shape[3],  # out_width\n","            MIN_FLOAT32  # Pass the minimum value as an argument\n","        )\n","        \n","        return output\n"]},{"cell_type":"markdown","metadata":{},"source":["### BatchNorm2d"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["@cuda.jit\n","def batchnorm2d_kernel(input: cuda.devicearray.DeviceNDArray,\n","                       output: cuda.devicearray.DeviceNDArray,\n","                       mean: cuda.devicearray.DeviceNDArray,\n","                       var: cuda.devicearray.DeviceNDArray,\n","                       eps: float,\n","                       gamma: cuda.devicearray.DeviceNDArray,\n","                       beta: cuda.devicearray.DeviceNDArray):\n","    \"\"\"\n","    A CUDA kernel that performs batch normalization on a 4D tensor.\n","\n","    Args:\n","        input (cuda.devicearray.DeviceNDArray): The input tensor.\n","        output (cuda.devicearray.DeviceNDArray): The output tensor.\n","        mean (cuda.devicearray.DeviceNDArray): The mean of the input tensor.\n","        var (cuda.devicearray.DeviceNDArray): The variance of the input tensor.\n","        eps (float): A small value added to the denominator for numerical stability.\n","        gamma (cuda.devicearray.DeviceNDArray): The scaling factor.\n","        beta (cuda.devicearray.DeviceNDArray): The shifting factor.\n","    \"\"\"\n","    idx, out_h, out_w = cuda.grid(3)\n","\n","    batch_idx = idx // input.shape[1]\n","    channel = idx % input.shape[1]\n","\n","    if batch_idx < output.shape[0] and channel < output.shape[1] and out_h < output.shape[2] and out_w < output.shape[3]:\n","        output[batch_idx, channel, out_h, out_w] = (input[batch_idx, channel, out_h, out_w] - mean[channel]) / math.sqrt(var[channel] + eps)\n","        \n","        if gamma is not None and beta is not None:\n","            output[batch_idx, channel, out_h, out_w] = output[batch_idx, channel, out_h, out_w] * gamma[channel] + beta[channel]\n","\n","\n","class NumbaBatchNorm2d(nn.Module):\n","    \"\"\"\n","    A PyTorch module that implements a batch normalization layer using Numba for acceleration.\n","\n","    This class is similar to `torch.nn.BatchNorm2d` but uses Numba to perform the mean and variance\n","    calculations on the GPU, potentially leading to faster execution.\n","\n","    Args:\n","        num_features (int): The number of features in the input tensor.\n","        eps (float, optional): A small value added to the denominator for numerical stability.\n","            Defaults to 1e-05.\n","        momentum (float, optional): The momentum used for running mean and variance computation.\n","            Defaults to 0.1.\n","        affine (bool, optional): If True, the layer will learn affine parameters (gamma and beta).\n","            Defaults to True.\n","        track_running_stats (bool, optional): If True, the layer will track running mean and variance.\n","            Defaults to True.\n","    \"\"\"\n","    def __init__(self,\n","                 num_features: int,\n","                 eps: float = 1e-05,\n","                 momentum: float = 0.1,\n","                 affine: bool = True,\n","                 track_running_stats: bool = True,) -> None:\n","        super().__init__()\n","\n","        self.eps = eps\n","        self.momentum = momentum\n","        self.track_running_stats = track_running_stats\n","\n","        if affine:\n","            self.gamma = nn.Parameter(data=torch.ones(num_features))\n","            self.beta = nn.Parameter(data=torch.zeros(num_features))\n","        else:\n","            self.register_parameter('gamma', None)\n","            self.register_parameter('beta', None)\n","\n","        if self.track_running_stats:\n","            self.running_mean = 0\n","            self.running_var = 1\n","        \n","    def forward(self, x: Tensor):\n","        assert x.is_cuda, \"Input must be a CUDA tensor\"\n","        assert x.dim() == 4, \"Input must be a 4D tensor\"\n","\n","        if self.training:\n","            # update running estimations\n","            if self.track_running_stats:\n","                self.running_mean = (1 - self.momentum) * self.running_mean + self.momentum * x.mean(dim=(0, 2, 3)) \n","                self.running_var = (1- self.momentum) * self.running_var + self.momentum * x.var(dim=(0, 2, 3), unbiased=True)\n","\n","            mean = x.mean(dim=(0, 2, 3)) # calculate mean over batch\n","            var = x.var(dim=(0, 2, 3), unbiased=False) # calculate variance over batch\n","        else:\n","            mean = self.running_mean.view((1, self.running_mean[0], 1, 1))\n","            var = self.running_var.view((1, self.running_var[0], 1, 1))\n","\n","        output = torch.zeros(x.shape, device=x.device)\n","        \n","        threads_per_block = (8, 8, 8)\n","        blocks_per_grid = (\n","            math.ceil(x.shape[0] * x.shape[1] / threads_per_block[0]),\n","            math.ceil(x.shape[2] / threads_per_block[1]),\n","            math.ceil(x.shape[3] / threads_per_block[2])\n","        )\n","\n","        batchnorm2d_kernel[blocks_per_grid, threads_per_block](\n","            x.detach(), output, mean.detach(), var.detach(), self.eps, self.gamma.detach(), self.beta.detach()\n","        )\n","\n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["### ReLU"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["@cuda.jit\n","def relu_kernel(input: cuda.devicearray.DeviceNDArray, output: cuda.devicearray.DeviceNDArray, dim: int):\n","    \"\"\"\n","    Applies ReLU activation to a CUDA array.\n","\n","    Args:\n","        input (cuda.devicearray.DeviceNDArray): The input CUDA array.\n","        output (cuda.devicearray.DeviceNDArray): The output CUDA array.\n","        dim (int): The total number of elements in the input and output arrays.\n","    \"\"\"\n","    idx = cuda.grid(1)\n","\n","    if idx < dim:\n","        output[idx] = max(input[idx], 0)\n","\n","\n","class NumbaReLU(nn.Module):\n","    \"\"\"\n","    Applies the ReLU function to a CUDA tensor using Numba.\n","\n","    Args:\n","        inplace (bool, optional): If set to `True`, the operation will be performed in-place. Defaults to `False`.\n","\n","    Shape:\n","        - Input: :math:`(N, *)` where `*` means, any number of additional dimensions\n","        - Output: :math:`(N, *)`, same shape as the input\n","\n","    Examples:\n","        >>> m = NumbaReLU()\n","        >>> input = torch.randn(2, 3, 4, 5, device='cuda')\n","        >>> output = m(input)\n","    \"\"\"\n","    def __init__(self, inplace: bool = False) -> None:\n","        super().__init__()\n","        self.inplace = inplace\n","\n","    def forward(self, x):\n","        assert x.is_cuda, \"Input must be a CUDA tensor\"\n","\n","        detached_x = x.detach().view(-1)\n","\n","        output = torch.zeros(x.shape, device=x.device).view(-1)\n","\n","        threads_per_block = 256\n","        dim = torch.prod(output.shape).item()\n","        blocks_per_grid = math.ceil(dim / threads_per_block)\n","\n","        relu_kernel[blocks_per_grid, threads_per_block](x.detach(), output, dim)\n","\n","        output = output.view(x.shape)\n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["### Linear"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["TPB = 32\n","\n","@cuda.jit\n","def linear_kernel(input, output, weight):\n","    \"\"\"\n","    Performs a matrix multiplication between two matrices using shared memory.\n","\n","    Args:\n","        input (cuda.device_array.DeviceNDArray): The input matrix.\n","        output (cuda.device_array.DeviceNDArray): The output matrix.\n","        weight (cuda.device_array.DeviceNDArray): The weight matrix.\n","    \"\"\"\n","    # Define an array in the shared memory\n","    # The size and type of the arrays must be known at compile time\n","    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n","    sB = cuda.shared.array(shape=(TPB, TPB), dtype=float32)\n","\n","    x, y = cuda.grid(2)\n","\n","    tx = cuda.threadIdx.x\n","    ty = cuda.threadIdx.y\n","    bpg = cuda.gridDim.x    # blocks per grid\n","\n","    # Each thread computes one element in the result matrix.\n","    # The dot product is chunked into dot products of TPB-long vectors.\n","    tmp = float32(0.)\n","    for i in range(bpg):\n","        # Preload data into shared memory\n","        sA[ty, tx] = 0\n","        sB[ty, tx] = 0\n","        if y < input.shape[0] and (tx+i*TPB) < input.shape[1]:\n","          sA[ty, tx] = input[y, tx + i * TPB]\n","        if x < weight.shape[1] and (ty+i*TPB) < weight.shape[0]:\n","          sB[ty, tx] = weight[ty + i * TPB, x]\n","\n","        # Wait until all threads finish preloading\n","        cuda.syncthreads()\n","\n","        # Computes partial product on the shared memory\n","        for j in range(TPB):\n","            tmp += sA[ty, j] * sB[j, tx]\n","\n","        # Wait until all threads finish computing\n","        cuda.syncthreads()\n","    if y < output.shape[0] and x < output.shape[1]:\n","        output[y, x] = tmp\n","        \n","\n","class NumbaLinear(nn.Module):\n","    \"\"\"\n","    Performs a linear transformation on a tensor using Numba CUDA.\n","\n","    This class implements a linear transformation with configurable input and output features, and optional bias.\n","    It leverages Numba CUDA for efficient GPU acceleration.\n","\n","    Args:\n","        in_features (int): The number of input features.\n","        out_features (int): The number of output features.\n","        bias (bool, optional): Whether to use a bias term. Defaults to True.\n","        custom_weight (torch.Tensor, optional): A custom weight tensor to use. Defaults to None.\n","        custom_bias (torch.Tensor, optional): A custom bias tensor to use. Defaults to None.\n","    \"\"\"\n","    def __init__(self,\n","                 in_features: int,\n","                 out_features: int,\n","                 bias: bool = True,\n","                 custom_weight = None,\n","                 custom_bias = None) -> None:\n","        super().__init__()\n","\n","        bound = math.sqrt(1.0 / in_features)\n","        self.weight = nn.Parameter(torch.rand(size=(out_features, in_features)) * 2 * bound - bound)\n","        if bias:\n","            self.bias = nn.Parameter(torch.rand(out_features) * 2 * bound - bound)\n","        else:\n","            self.register_parameter('bias', None)\n","            \n","        if custom_weight is not None:\n","            self.weight = custom_weight\n","        if custom_bias is not None:\n","            self.bias = custom_bias\n","\n","    def forward(self, x):\n","        assert x.is_cuda, \"Input must be a CUDA tensor\"\n","        assert self.weight.is_cuda, \"Weights must be CUDA tensors\"\n","        assert self.bias is None or self.bias.is_cuda, \"Bias must be a CUDA tensor if it exists\"\n","\n","        original_shape = x.shape\n","        detached_x = x.detach()\n","        if x.dim() > 2:\n","            detached_x = detached_x.flatten(0, -2)\n","\n","        output = torch.empty(detached_x.size(0), self.weight.shape[0], device=x.device)\n","        \n","        threads_per_block = (TPB, TPB)\n","        grid_y_max = max(detached_x.shape[0], self.weight.shape[0])\n","        grid_x_max = max(detached_x.shape[1], self.weight.shape[1])\n","\n","        blocks_per_grid_x = math.ceil(grid_x_max / threads_per_block[0])\n","        blocks_per_grid_y = math.ceil(grid_y_max / threads_per_block[1])\n","\n","        blocks_per_grid = (blocks_per_grid_x, blocks_per_grid_y)\n","        linear_kernel[blocks_per_grid, threads_per_block](\n","            detached_x, output, self.weight.detach().T\n","        )\n","\n","        if self.bias is not None:\n","            output += self.bias\n","        \n","        output = output.view(*original_shape[:-1], output.shape[-1])\n","        return output"]},{"cell_type":"markdown","metadata":{},"source":["### Numba ResNet9"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class NumbaConvBlock(nn.Module):\n","    def __init__(self,\n","                 in_channels: int,\n","                 out_channels: int,\n","                 kernel: int = 3,\n","                 stride: int = 1,\n","                 padding: int = 1,\n","                 pooling: bool = False,\n","                 pooling_kernel: int = 4) -> None:\n","    \n","        super().__init__()\n","\n","        self.conv = nn.Sequential(\n","            NumbaConv2d(in_channels, out_channels, kernel_size=kernel, stride=stride, padding=padding),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        if pooling:\n","            self.conv.append(NumbaMaxPool2d(kernel_size=pooling_kernel))\n","\n","    def forward(self, X: Tensor):\n","        return self.conv(X)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class NumbaResNet9(nn.Module):\n","    def __init__(self,\n","                 in_channels: int,\n","                 num_classes: int,) -> None:\n","        super().__init__()\n","\n","        self.conv1 = NumbaConvBlock(in_channels=in_channels, out_channels=64)\n","        self.conv2 = NumbaConvBlock(in_channels=64, out_channels=128, pooling=True)\n","        \n","        self.residual1 = nn.Sequential(\n","            NumbaConvBlock(128, 128),\n","            NumbaConvBlock(128, 128)\n","        )\n","\n","        self.conv3 = NumbaConvBlock(in_channels=128, out_channels=256, pooling=True)\n","        self.conv4 = NumbaConvBlock(in_channels=256, out_channels=512, pooling=True)\n","        \n","        self.residual2 = nn.Sequential(\n","            NumbaConvBlock(512, 512),\n","            NumbaConvBlock(512, 512)\n","        )\n","        \n","        self.classifier = nn.Sequential(\n","            NumbaMaxPool2d(4),\n","            nn.Flatten(),\n","            nn.Linear(in_features=512, out_features=num_classes)\n","        )\n","\n","    def forward(self, x: Tensor):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.residual1(x) + x\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = self.residual2(x) + x\n","        x = self.classifier(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["## ResNet9"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T17:46:15.156679Z","iopub.status.busy":"2024-07-09T17:46:15.156355Z","iopub.status.idle":"2024-07-09T17:46:15.168482Z","shell.execute_reply":"2024-07-09T17:46:15.167556Z","shell.execute_reply.started":"2024-07-09T17:46:15.156649Z"},"trusted":true},"outputs":[],"source":["class ConvBlock(nn.Module):\n","    def __init__(self,\n","                 in_channels: int,\n","                 out_channels: int,\n","                 kernel: int = 3,\n","                 stride: int = 1,\n","                 padding: int = 1,\n","                 pooling: bool = False,\n","                 pooling_kernel: int = 4) -> None:\n","    \n","        super().__init__()\n","\n","        self.conv = nn.Sequential(\n","            nn.Conv2d(in_channels, out_channels, kernel_size=kernel, stride=stride, padding=padding),\n","            nn.BatchNorm2d(out_channels),\n","            nn.ReLU(inplace=True)\n","        )\n","\n","        if pooling:\n","            self.conv.append(nn.MaxPool2d(kernel_size=pooling_kernel))\n","\n","    def forward(self, X: Tensor):\n","        return self.conv(X)\n"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T17:46:15.170883Z","iopub.status.busy":"2024-07-09T17:46:15.169944Z","iopub.status.idle":"2024-07-09T17:46:15.181822Z","shell.execute_reply":"2024-07-09T17:46:15.180920Z","shell.execute_reply.started":"2024-07-09T17:46:15.170858Z"},"trusted":true},"outputs":[],"source":["class ResNet9(nn.Module):\n","    def __init__(self,\n","                 in_channels: int,\n","                 num_classes: int,) -> None:\n","        super().__init__()\n","\n","        self.conv1 = ConvBlock(in_channels=in_channels, out_channels=64)\n","        self.conv2 = ConvBlock(in_channels=64, out_channels=128, pooling=True)\n","\n","        self.residual1 = nn.Sequential(\n","            ConvBlock(128, 128),\n","            ConvBlock(128, 128)\n","        )\n","\n","        self.conv3 = ConvBlock(in_channels=128, out_channels=256, pooling=True)\n","        self.conv4 = ConvBlock(in_channels=256, out_channels=512, pooling=True)\n","\n","        self.residual2 = nn.Sequential(\n","            ConvBlock(512, 512),\n","            ConvBlock(512, 512)\n","        )\n","\n","        self.classifier = nn.Sequential(\n","            nn.MaxPool2d(4),\n","            nn.Flatten(),\n","            nn.Linear(in_features=512, out_features=num_classes)\n","        )\n","\n","    def forward(self, x: Tensor):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.residual1(x) + x\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = self.residual2(x) + x\n","        x = self.classifier(x)\n","\n","        return x"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T17:46:15.146424Z","iopub.status.busy":"2024-07-09T17:46:15.146117Z","iopub.status.idle":"2024-07-09T17:46:15.154784Z","shell.execute_reply":"2024-07-09T17:46:15.153838Z","shell.execute_reply.started":"2024-07-09T17:46:15.146393Z"},"trusted":true},"outputs":[],"source":["class PlantDiseaseDataset(Dataset):\n","    \"\"\"\n","    A PyTorch Dataset class for plant disease classification.\n","\n","    This class loads images from a specified directory and applies optional transformations.\n","    It assumes the directory structure follows the ImageFolder convention, where each subdirectory\n","    represents a different disease class.\n","\n","    If no transformations are provided (`transforms` is None), the class will convert the images\n","    to PyTorch tensors by default.\n","\n","    Args:\n","        path (str): The path to the directory containing the plant disease images.\n","        transforms (Callable, optional): A callable object (e.g., torchvision.transforms)\n","            to apply to the images. Defaults to None.\n","    \"\"\"\n","    def __init__(self,\n","                 path: str,\n","                 transform_function: Optional[Callable] = None) -> None:\n","        super().__init__()\n","\n","        transform = transform_function or transforms.ToTensor()\n","        self.img_folder = ImageFolder(path, transform=transform)\n","\n","    def __len__(self) -> int:\n","        return len(self.img_folder)\n","    \n","    def __getitem__(self, idx) -> Tuple[Tensor, int]:\n","        return self.img_folder[idx]"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-07-09T09:07:47.346808Z","iopub.status.busy":"2024-07-09T09:07:47.346155Z","iopub.status.idle":"2024-07-09T09:07:47.351254Z","shell.execute_reply":"2024-07-09T09:07:47.350435Z","shell.execute_reply.started":"2024-07-09T09:07:47.346775Z"}},"source":["## Train"]},{"cell_type":"markdown","metadata":{},"source":["**Load dataset**"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T17:46:15.194887Z","iopub.status.busy":"2024-07-09T17:46:15.194456Z","iopub.status.idle":"2024-07-09T17:46:27.365099Z","shell.execute_reply":"2024-07-09T17:46:27.364066Z","shell.execute_reply.started":"2024-07-09T17:46:15.194853Z"},"trusted":true},"outputs":[],"source":["data_path = './data/New-Plant-Diseases-Dataset/'\n","\n","train_dataset = PlantDiseaseDataset(data_path + 'train')\n","val_dataset = PlantDiseaseDataset(data_path + 'valid')"]},{"cell_type":"markdown","metadata":{},"source":["Just use a subset of dataset"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T17:46:27.367044Z","iopub.status.busy":"2024-07-09T17:46:27.366627Z","iopub.status.idle":"2024-07-09T17:46:27.371589Z","shell.execute_reply":"2024-07-09T17:46:27.370497Z","shell.execute_reply.started":"2024-07-09T17:46:27.367008Z"},"trusted":true},"outputs":[],"source":["# train_dataset = Subset(train_dataset, torch.linspace(0, len(train_dataset), 1000).type(torch.int))\n","# val_dataset = Subset(val_dataset, torch.linspace(0, len(val_dataset), 100).type(torch.int))"]},{"cell_type":"markdown","metadata":{},"source":["**Data Loader**"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T17:46:27.373146Z","iopub.status.busy":"2024-07-09T17:46:27.372816Z","iopub.status.idle":"2024-07-09T17:46:27.381353Z","shell.execute_reply":"2024-07-09T17:46:27.380501Z","shell.execute_reply.started":"2024-07-09T17:46:27.373109Z"},"trusted":true},"outputs":[],"source":["batch_size = 128\n","train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-07-09T09:23:49.389129Z","iopub.status.busy":"2024-07-09T09:23:49.388572Z","iopub.status.idle":"2024-07-09T09:23:49.395104Z","shell.execute_reply":"2024-07-09T09:23:49.393962Z","shell.execute_reply.started":"2024-07-09T09:23:49.389096Z"}},"source":["**Loss, Optimizer**"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T17:46:27.382822Z","iopub.status.busy":"2024-07-09T17:46:27.382513Z","iopub.status.idle":"2024-07-09T17:46:27.598978Z","shell.execute_reply":"2024-07-09T17:46:27.598045Z","shell.execute_reply.started":"2024-07-09T17:46:27.382797Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DataParallel(\n","  (module): NumbaResNet9(\n","    (conv1): NumbaConvBlock(\n","      (conv): Sequential(\n","        (0): NumbaConv2d()\n","        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","      )\n","    )\n","    (conv2): NumbaConvBlock(\n","      (conv): Sequential(\n","        (0): NumbaConv2d()\n","        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): NumbaMaxPool2d()\n","      )\n","    )\n","    (residual1): Sequential(\n","      (0): NumbaConvBlock(\n","        (conv): Sequential(\n","          (0): NumbaConv2d()\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","      )\n","      (1): NumbaConvBlock(\n","        (conv): Sequential(\n","          (0): NumbaConv2d()\n","          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (conv3): NumbaConvBlock(\n","      (conv): Sequential(\n","        (0): NumbaConv2d()\n","        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): NumbaMaxPool2d()\n","      )\n","    )\n","    (conv4): NumbaConvBlock(\n","      (conv): Sequential(\n","        (0): NumbaConv2d()\n","        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","        (2): ReLU(inplace=True)\n","        (3): NumbaMaxPool2d()\n","      )\n","    )\n","    (residual2): Sequential(\n","      (0): NumbaConvBlock(\n","        (conv): Sequential(\n","          (0): NumbaConv2d()\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","      )\n","      (1): NumbaConvBlock(\n","        (conv): Sequential(\n","          (0): NumbaConv2d()\n","          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","          (2): ReLU(inplace=True)\n","        )\n","      )\n","    )\n","    (classifier): Sequential(\n","      (0): NumbaMaxPool2d()\n","      (1): Flatten(start_dim=1, end_dim=-1)\n","      (2): Linear(in_features=512, out_features=38, bias=True)\n","    )\n","  )\n",")"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["model = NumbaResNet9(3, 38)\n","model = nn.DataParallel(model, device_ids=[0, 1])\n","model.to(device)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T17:46:27.600824Z","iopub.status.busy":"2024-07-09T17:46:27.600440Z","iopub.status.idle":"2024-07-09T17:46:27.606503Z","shell.execute_reply":"2024-07-09T17:46:27.605479Z","shell.execute_reply.started":"2024-07-09T17:46:27.600789Z"},"trusted":true},"outputs":[],"source":["criterion = nn.CrossEntropyLoss().cuda()\n","\n","optimizer = optim.AdamW(params=model.parameters(), lr=1e-5)"]},{"cell_type":"markdown","metadata":{},"source":["**Training loop**"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T17:46:27.610305Z","iopub.status.busy":"2024-07-09T17:46:27.609992Z","iopub.status.idle":"2024-07-09T17:46:27.617484Z","shell.execute_reply":"2024-07-09T17:46:27.616609Z","shell.execute_reply.started":"2024-07-09T17:46:27.610279Z"},"trusted":true},"outputs":[],"source":["epochs = 10"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-07-09T17:46:27.618957Z","iopub.status.busy":"2024-07-09T17:46:27.618592Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Training Epoch 1:   1%|‚ñè         | 7/550 [01:30<1:55:37, 12.78s/it, loss=5.23]"]}],"source":["for epoch in range(epochs):\n","    running_loss = 0.0\n","    \n","    train_loop = tqdm(train_dataloader, desc=f'Training Epoch {epoch + 1}', leave=True)\n","    for i, data in enumerate(train_loop):\n","        X, y = (_.cuda() for _ in data)\n","        \n","        y_pred = model(X)\n","        \n","        loss = criterion(y_pred, y)\n","        loss.backward()\n","        optimizer.step()\n","        optimizer.zero_grad()\n","        \n","        running_loss += loss.item()\n","        \n","        train_loop.set_postfix({'loss': running_loss / (i + 1)})"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":78313,"sourceId":182633,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":4}
