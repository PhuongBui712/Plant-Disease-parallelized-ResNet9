{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "055ae099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "from typing import Optional, Callable, Tuple\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be39eabb",
   "metadata": {},
   "source": [
    "## Define classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a970a876",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3fdd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantDiseaseDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset class for plant disease classification.\n",
    "\n",
    "    This class loads images from a specified directory and applies optional transformations.\n",
    "    It assumes the directory structure follows the ImageFolder convention, where each subdirectory\n",
    "    represents a different disease class.\n",
    "\n",
    "    If no transformations are provided (`transforms` is None), the class will convert the images\n",
    "    to PyTorch tensors by default.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to the directory containing the plant disease images.\n",
    "        transforms (Callable, optional): A callable object (e.g., torchvision.transforms)\n",
    "            to apply to the images. Defaults to None.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 path: str,\n",
    "                 transform_function: Optional[Callable] = None) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        transform = transform_function or transforms.ToTensor()\n",
    "        self.img_folder = ImageFolder(path, transform=transform)\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.img_folder)\n",
    "    \n",
    "    def __getitem__(self, idx) -> Tuple[Tensor, int]:\n",
    "        return self.img_folder[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71488ccc",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a2bbb9",
   "metadata": {},
   "source": [
    "#### Numba layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15c43e6",
   "metadata": {},
   "source": [
    "##### Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb492781",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def conv2d_kernel(input, kernel, output, padding, stride):\n",
    "    combined_idx, out_y, out_x = cuda.grid(3)\n",
    "    batch_size, in_channels, in_height, in_width = input.shape\n",
    "    out_channels, _, kernel_height, kernel_width = kernel.shape\n",
    "    out_height, out_width = output.shape[2:]\n",
    "\n",
    "    batch_idx = combined_idx // out_channels\n",
    "    out_channel_idx = combined_idx % out_channels\n",
    "\n",
    "    if batch_idx < batch_size and out_channel_idx < out_channels and out_y < out_height and out_x < out_width:\n",
    "        res = 0.0\n",
    "        for in_channel in range(in_channels):\n",
    "            for ky in range(kernel_height):\n",
    "                for kx in range(kernel_width):\n",
    "                    in_y = out_y * stride - padding + ky\n",
    "                    in_x = out_x * stride - padding + kx\n",
    "                    if 0 <= in_y < in_height and 0 <= in_x < in_width:\n",
    "                        res += input[batch_idx, in_channel, in_y, in_x] * kernel[out_channel_idx, in_channel, ky, kx]\n",
    "        output[batch_idx, out_channel_idx, out_y, out_x] = res\n",
    "\n",
    "class NumbaConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, padding=0, stride=1, weight=None, bias=None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernel = weight\n",
    "        if self.kernel is None:\n",
    "            self.kernel = nn.Parameter(torch.randn(out_channels, in_channels, kernel_size, kernel_size, device='cuda'))\n",
    "\n",
    "        self.bias = bias\n",
    "        if self.bias is None:\n",
    "            self.bias = nn.Parameter(torch.zeros(out_channels, device='cuda'))\n",
    "\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.is_cuda, \"Input must be a CUDA tensor\"\n",
    "        assert x.dim() == 4, \"Input must be a 4D tensor\"\n",
    "\n",
    "        # Ensure input and kernel are in the same precision\n",
    "        detached_x = x.detach()\n",
    "        detached_kernel = self.kernel.detach()\n",
    "\n",
    "        batch_size, in_channels, in_height, in_width = x.shape\n",
    "        out_channels, _, kernel_height, kernel_width = self.kernel.shape\n",
    "        out_height = (in_height + 2 * self.padding - kernel_height) // self.stride + 1\n",
    "        out_width = (in_width + 2 * self.padding - kernel_width) // self.stride + 1\n",
    "\n",
    "        output = torch.zeros(batch_size, out_channels, out_height, out_width,\n",
    "                             dtype=torch.float32, device=x.device)\n",
    "\n",
    "        threads_per_block = (8, 8, 8)\n",
    "        blocks_per_grid = (\n",
    "            (batch_size * out_channels + threads_per_block[0] - 1) // threads_per_block[0],\n",
    "            (out_height + threads_per_block[1] - 1) // threads_per_block[1],\n",
    "            (out_width + threads_per_block[2] - 1) // threads_per_block[2]\n",
    "        )\n",
    "\n",
    "        conv2d_kernel[blocks_per_grid, threads_per_block](\n",
    "            detached_x, detached_kernel, output, self.padding, self.stride\n",
    "        )\n",
    "\n",
    "        return output + self.bias.view(1, -1, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd76d847",
   "metadata": {},
   "source": [
    "##### MaxPool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1235348",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_FLOAT32 = torch.finfo(torch.float32).min\n",
    "\n",
    "@cuda.jit\n",
    "def max_pool_2d_kernel(input, output, kernel_size, padding, stride):\n",
    "    idx, out_h, out_w = cuda.grid(3)\n",
    "    \n",
    "    batch_idx = idx // input.shape[1]\n",
    "    channel = idx % input.shape[1]\n",
    "    \n",
    "    if batch_idx < input.shape[0] and channel < input.shape[1] and out_h < input.shape[2] and out_w < input.shape[3]:\n",
    "        for ky in range(kernel_size):\n",
    "            for kx in range(kernel_size):\n",
    "                in_y = out_h * stride - padding + ky\n",
    "                in_x = out_w * stride - padding +kx\n",
    "\n",
    "                if 0 <= in_y < input.shape[2] and 0 <= in_x < input.shape[3]:\n",
    "                    output[batch_idx, channel, out_h, out_w] = max(output[batch_idx, channel, out_h, out_w],\n",
    "                                                                   input[batch_idx, channel, in_y, in_x])\n",
    "                                                                 \n",
    "\n",
    "\n",
    "class NumbaMaxPool2d(nn.Module):\n",
    "    def __init__(self, kernel_size, padding=0, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.is_cuda, \"Input must be a CUDA tensor\"\n",
    "        assert x.dim() == 4, \"Input must be a 4D tensor\"\n",
    "\n",
    "        detached_x = x.detach()\n",
    "\n",
    "        batch_size, channels, in_height, in_width = x.shape\n",
    "        out_height = (in_height + 2 * self.padding - (self.kernel_size - 1) - 1) // self.stride + 1\n",
    "        out_width = (in_width + 2 * self.padding - (self.kernel_size - 1) - 1) // self.stride + 1\n",
    "\n",
    "        output = torch.full(\n",
    "            size=(batch_size, channels, out_height, out_width),\n",
    "            fill_value=MIN_FLOAT32,\n",
    "            device=x.device\n",
    "        )\n",
    "        \n",
    "        threads_per_block = (8, 8, 8)\n",
    "        blocks_per_grid = (\n",
    "            math.ceil(batch_size * channels / threads_per_block[0]),\n",
    "            math.ceil(out_height / threads_per_block[1]),\n",
    "            math.ceil(out_width / threads_per_block[2])\n",
    "        )\n",
    "\n",
    "        max_pool_2d_kernel[blocks_per_grid, threads_per_block](\n",
    "            detached_x, output, self.kernel_size, self.padding, self.stride\n",
    "        )\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6e35ae",
   "metadata": {},
   "source": [
    "#### ResNet9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd8e44ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel: Optional[int] = 3,\n",
    "                 stride: Optional[int] = 1,\n",
    "                 padding: Optional[int] = 1,\n",
    "                 pooling: Optional[bool] = False,\n",
    "                 pooling_kernel: Optional[int] = 4) -> None:\n",
    "    \n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        if pooling:\n",
    "            self.conv.append(nn.MaxPool2d(kernel_size=pooling_kernel))\n",
    "\n",
    "    def forward(self, X: Tensor):\n",
    "        return self.conv(X)\n",
    "    \n",
    "\n",
    "class NumbaConvBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel: Optional[int] = 3,\n",
    "                 stride: Optional[int] = 1,\n",
    "                 padding: Optional[int] = 1,\n",
    "                 pooling: Optional[bool] = False,\n",
    "                 pooling_kernel: Optional[int] = 4) -> None:\n",
    "    \n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            NumbaConv2d(in_channels, out_channels, kernel_size=kernel, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        if pooling:\n",
    "            self.conv.append(NumbaMaxPool2d(kernel_size=pooling_kernel))\n",
    "\n",
    "    def forward(self, X: Tensor):\n",
    "        return self.conv(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aab7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumbaResNet9(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 num_classes: int,) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = NumbaConvBlock(in_channels=in_channels, out_channels=64)\n",
    "        self.conv2 = NumbaConvBlock(in_channels=64, out_channels=128, pooling=True)\n",
    "        \n",
    "        self.residual1 = nn.Sequential(\n",
    "            NumbaConvBlock(128, 128),\n",
    "            NumbaConvBlock(128, 128)\n",
    "        )\n",
    "\n",
    "        self.conv3 = NumbaConvBlock(in_channels=128, out_channels=256, pooling=True)\n",
    "        self.conv4 = NumbaConvBlock(in_channels=256, out_channels=512, pooling=True)\n",
    "        \n",
    "        self.residual2 = nn.Sequential(\n",
    "            NumbaConvBlock(512, 512),\n",
    "            NumbaConvBlock(512, 512)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            NumbaMaxPool2d(4),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=512, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        x = self.conv1(x)\n",
    "        print(1)\n",
    "        x = self.conv2(x)\n",
    "        print(2)\n",
    "        x = self.residual1(x) + x\n",
    "        print(3)\n",
    "        x = self.conv3(x)\n",
    "        print(4)\n",
    "        x = self.conv4(x)\n",
    "        print(5)\n",
    "        x = self.classifier(x)\n",
    "        print(6)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e360241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet9(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 num_classes: int,) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = ConvBlock(in_channels=in_channels, out_channels=64)\n",
    "        self.conv2 = ConvBlock(in_channels=64, out_channels=128, pooling=True)\n",
    "\n",
    "        self.residual1 = nn.Sequential(\n",
    "            ConvBlock(128, 128),\n",
    "            ConvBlock(128, 128)\n",
    "        )\n",
    "\n",
    "        self.conv3 = ConvBlock(in_channels=128, out_channels=256, pooling=True)\n",
    "        self.conv4 = ConvBlock(in_channels=256, out_channels=512, pooling=True)\n",
    "\n",
    "        self.residual2 = nn.Sequential(\n",
    "            ConvBlock(512, 512),\n",
    "            ConvBlock(512, 512)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.MaxPool2d(4),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=512, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.residual1(x) + x\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.residual2(x) + x\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a5d648",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0cab3b47",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "value cannot be converted to type int16_t without overflow",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m PlantDiseaseDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/New-Plant-Diseases-Dataset/train\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m PlantDiseaseDataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/New-Plant-Diseases-Dataset/valid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m Subset(train_dataset, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinspace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint16\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m Subset(val_dataset, torch\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(val_dataset), \u001b[38;5;241m100\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint16))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: value cannot be converted to type int16_t without overflow"
     ]
    }
   ],
   "source": [
    "train_dataset = PlantDiseaseDataset('data/New-Plant-Diseases-Dataset/train')\n",
    "val_dataset = PlantDiseaseDataset('data/New-Plant-Diseases-Dataset/valid')\n",
    "\n",
    "train_dataset = Subset(train_dataset, torch.linspace(0, len(train_dataset), 1000, dtype=torch.int16))\n",
    "val_dataset = Subset(val_dataset, torch.linspace(0, len(val_dataset), 100, dtype=torch.int16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b03f434",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn.Conv2d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
