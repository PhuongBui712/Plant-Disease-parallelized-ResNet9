{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":182633,"sourceType":"datasetVersion","datasetId":78313}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import libraries","metadata":{}},{"cell_type":"code","source":"import math\nimport numpy as np\nfrom tqdm import tqdm\nfrom numba import cuda\nfrom typing import Optional, Callable, Tuple\n\nimport torch\nfrom torch import Tensor\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch import optim\n\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torchvision.datasets import ImageFolder\nfrom torchvision import transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-09T17:46:11.726893Z","iopub.execute_input":"2024-07-09T17:46:11.727576Z","iopub.status.idle":"2024-07-09T17:46:15.093609Z","shell.execute_reply.started":"2024-07-09T17:46:11.727542Z","shell.execute_reply":"2024-07-09T17:46:15.092625Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0')","metadata":{"execution":{"iopub.status.busy":"2024-07-09T17:46:15.095976Z","iopub.execute_input":"2024-07-09T17:46:15.096514Z","iopub.status.idle":"2024-07-09T17:46:15.100404Z","shell.execute_reply.started":"2024-07-09T17:46:15.096477Z","shell.execute_reply":"2024-07-09T17:46:15.099550Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Implement ResNet9 with Numba","metadata":{}},{"cell_type":"markdown","source":"**Test tensor**","metadata":{}},{"cell_type":"markdown","source":"### Conv2d","metadata":{}},{"cell_type":"code","source":"@cuda.jit\ndef conv2d_kernel(input, kernel, output, padding, stride):\n    combined_idx, out_y, out_x = cuda.grid(3)\n    batch_size, in_channels, in_height, in_width = input.shape\n    out_channels, _, kernel_height, kernel_width = kernel.shape\n    out_height, out_width = output.shape[2:]\n\n    batch_idx = combined_idx // out_channels\n    out_channel_idx = combined_idx % out_channels\n\n    if batch_idx < batch_size and out_channel_idx < out_channels and out_y < out_height and out_x < out_width:\n        res = 0.0\n        for in_channel in range(in_channels):\n            for ky in range(kernel_height):\n                for kx in range(kernel_width):\n                    in_y = out_y * stride - padding + ky\n                    in_x = out_x * stride - padding + kx\n                    if 0 <= in_y < in_height and 0 <= in_x < in_width:\n                        res += input[batch_idx, in_channel, in_y, in_x] * kernel[out_channel_idx, in_channel, ky, kx]\n        output[batch_idx, out_channel_idx, out_y, out_x] = res\n\nclass NumbaConv2d(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size, padding=0, stride=None, weight=None, bias=None):\n        super().__init__()\n\n        self.kernel = weight\n        if self.kernel is None:\n            self.kernel = nn.Parameter(torch.randn(out_channels, in_channels, kernel_size, kernel_size, device='cuda'))\n\n        self.bias = bias\n        if self.bias is None:\n            self.bias = nn.Parameter(torch.zeros(out_channels, device='cuda'))\n\n        self.padding = padding\n        self.stride = stride\n\n    def forward(self, x):\n        assert x.is_cuda, \"Input must be a CUDA tensor\"\n        assert x.dim() == 4, \"Input must be a 4D tensor\"\n\n        # Ensure input and kernel are in the same precision\n        detached_x = x.detach()\n        detached_kernel = self.kernel.detach()\n\n        batch_size, in_channels, in_height, in_width = x.shape\n        out_channels, _, kernel_height, kernel_width = self.kernel.shape\n        out_height = (in_height + 2 * self.padding - kernel_height) // self.stride + 1\n        out_width = (in_width + 2 * self.padding - kernel_width) // self.stride + 1\n\n        output = torch.zeros(batch_size, out_channels, out_height, out_width,\n                             dtype=torch.float32, device=x.device)\n\n        threads_per_block = (8, 8, 8)\n        blocks_per_grid = (\n            (batch_size * out_channels + threads_per_block[0] - 1) // threads_per_block[0],\n            (out_height + threads_per_block[1] - 1) // threads_per_block[1],\n            (out_width + threads_per_block[2] - 1) // threads_per_block[2]\n        )\n\n        conv2d_kernel[blocks_per_grid, threads_per_block](\n            detached_x, detached_kernel, output, self.padding, self.stride\n        )\n\n        return output + self.bias.view(1, -1, 1, 1)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T17:46:15.102078Z","iopub.execute_input":"2024-07-09T17:46:15.102719Z","iopub.status.idle":"2024-07-09T17:46:15.126188Z","shell.execute_reply.started":"2024-07-09T17:46:15.102667Z","shell.execute_reply":"2024-07-09T17:46:15.125097Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"### MaxPool2d","metadata":{}},{"cell_type":"code","source":"MIN_FLOAT32 = torch.finfo(torch.float32).min\n\n@cuda.jit\ndef max_pool_2d_kernel(input, output, kernel_size, padding, stride):\n    idx, out_h, out_w = cuda.grid(3)\n    \n    batch_idx = idx // output.shape[1]\n    channel = idx % output.shape[1]\n    \n    if batch_idx < output.shape[0] and channel < output.shape[1] and out_h < output.shape[2] and out_w < output.shape[3]:\n        for ky in range(kernel_size):\n            for kx in range(kernel_size):\n                in_y = out_h * stride - padding + ky\n                in_x = out_w * stride - padding +kx\n\n                if 0 <= in_y < input.shape[2] and 0 <= in_x < input.shape[3]:\n                    output[batch_idx, channel, out_h, out_w] = max(output[batch_idx, channel, out_h, out_w],\n                                                                   input[batch_idx, channel, in_y, in_x])\n                                                                 \n\n\nclass NumbaMaxPool2d(nn.Module):\n    def __init__(self, kernel_size, padding=0, stride=None):\n        super().__init__()\n\n        self.kernel_size = kernel_size\n        self.padding = padding\n        self.stride = stride or kernel_size\n\n    def forward(self, x):\n        assert x.is_cuda, \"Input must be a CUDA tensor\"\n        assert x.dim() == 4, \"Input must be a 4D tensor\"\n\n        detached_x = x.detach()\n\n        batch_size, channels, in_height, in_width = x.shape\n        out_height = (in_height + 2 * self.padding - (self.kernel_size - 1) - 1) // self.stride + 1\n        out_width = (in_width + 2 * self.padding - (self.kernel_size - 1) - 1) // self.stride + 1\n\n        output = torch.full(\n            size=(batch_size, channels, out_height, out_width),\n            fill_value=MIN_FLOAT32,\n            device=x.device\n        )\n        \n        threads_per_block = (8, 8, 8)\n        blocks_per_grid = (\n            math.ceil(batch_size * channels / threads_per_block[0]),\n            math.ceil(out_height / threads_per_block[1]),\n            math.ceil(out_width / threads_per_block[2])\n        )\n\n        max_pool_2d_kernel[blocks_per_grid, threads_per_block](\n            detached_x, output, self.kernel_size, self.padding, self.stride\n        )\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-07-09T17:46:15.127551Z","iopub.execute_input":"2024-07-09T17:46:15.127859Z","iopub.status.idle":"2024-07-09T17:46:15.142615Z","shell.execute_reply.started":"2024-07-09T17:46:15.127833Z","shell.execute_reply":"2024-07-09T17:46:15.141611Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"class PlantDiseaseDataset(Dataset):\n    \"\"\"\n    A PyTorch Dataset class for plant disease classification.\n\n    This class loads images from a specified directory and applies optional transformations.\n    It assumes the directory structure follows the ImageFolder convention, where each subdirectory\n    represents a different disease class.\n\n    If no transformations are provided (`transforms` is None), the class will convert the images\n    to PyTorch tensors by default.\n\n    Args:\n        path (str): The path to the directory containing the plant disease images.\n        transforms (Callable, optional): A callable object (e.g., torchvision.transforms)\n            to apply to the images. Defaults to None.\n    \"\"\"\n    def __init__(self,\n                 path: str,\n                 transform_function: Optional[Callable] = None) -> None:\n        super().__init__()\n\n        transform = transform_function or transforms.ToTensor()\n        self.img_folder = ImageFolder(path, transform=transform)\n\n    def __len__(self) -> int:\n        return len(self.img_folder)\n    \n    def __getitem__(self, idx) -> Tuple[Tensor, int]:\n        return self.img_folder[idx]","metadata":{"execution":{"iopub.status.busy":"2024-07-09T17:46:15.146117Z","iopub.execute_input":"2024-07-09T17:46:15.146424Z","iopub.status.idle":"2024-07-09T17:46:15.154784Z","shell.execute_reply.started":"2024-07-09T17:46:15.146393Z","shell.execute_reply":"2024-07-09T17:46:15.153838Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## ResNet9","metadata":{}},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self,\n                 in_channels: int,\n                 out_channels: int,\n                 kernel: int = 3,\n                 stride: int = 1,\n                 padding: int = 1,\n                 pooling: bool = False,\n                 pooling_kernel: int = 4) -> None:\n    \n        super().__init__()\n\n        self.conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=kernel, stride=stride, padding=padding),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n        if pooling:\n            self.conv.append(nn.MaxPool2d(kernel_size=pooling_kernel))\n\n    def forward(self, X: Tensor):\n        return self.conv(X)\n    \n\nclass NumbaConvBlock(nn.Module):\n    def __init__(self,\n                 in_channels: int,\n                 out_channels: int,\n                 kernel: int = 3,\n                 stride: int = 1,\n                 padding: int = 1,\n                 pooling: bool = False,\n                 pooling_kernel: int = 4) -> None:\n    \n        super().__init__()\n\n        self.conv = nn.Sequential(\n            NumbaConv2d(in_channels, out_channels, kernel_size=kernel, stride=stride, padding=padding),\n            nn.BatchNorm2d(out_channels),\n            nn.ReLU(inplace=True)\n        )\n\n        if pooling:\n            self.conv.append(NumbaMaxPool2d(kernel_size=pooling_kernel))\n\n    def forward(self, X: Tensor):\n        return self.conv(X)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T17:46:15.156355Z","iopub.execute_input":"2024-07-09T17:46:15.156679Z","iopub.status.idle":"2024-07-09T17:46:15.168482Z","shell.execute_reply.started":"2024-07-09T17:46:15.156649Z","shell.execute_reply":"2024-07-09T17:46:15.167556Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class ResNet9(nn.Module):\n    def __init__(self,\n                 in_channels: int,\n                 num_classes: int,) -> None:\n        super().__init__()\n\n        self.conv1 = ConvBlock(in_channels=in_channels, out_channels=64)\n        self.conv2 = ConvBlock(in_channels=64, out_channels=128, pooling=True)\n\n        self.residual1 = nn.Sequential(\n            ConvBlock(128, 128),\n            ConvBlock(128, 128)\n        )\n\n        self.conv3 = ConvBlock(in_channels=128, out_channels=256, pooling=True)\n        self.conv4 = ConvBlock(in_channels=256, out_channels=512, pooling=True)\n\n        self.residual2 = nn.Sequential(\n            ConvBlock(512, 512),\n            ConvBlock(512, 512)\n        )\n\n        self.classifier = nn.Sequential(\n            nn.MaxPool2d(4),\n            nn.Flatten(),\n            nn.Linear(in_features=512, out_features=num_classes)\n        )\n\n    def forward(self, x: Tensor):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.residual1(x) + x\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.residual2(x) + x\n        x = self.classifier(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-07-09T17:46:15.169944Z","iopub.execute_input":"2024-07-09T17:46:15.170883Z","iopub.status.idle":"2024-07-09T17:46:15.181822Z","shell.execute_reply.started":"2024-07-09T17:46:15.170858Z","shell.execute_reply":"2024-07-09T17:46:15.180920Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"class NumbaResNet9(nn.Module):\n    def __init__(self,\n                 in_channels: int,\n                 num_classes: int,) -> None:\n        super().__init__()\n\n        self.conv1 = NumbaConvBlock(in_channels=in_channels, out_channels=64)\n        self.conv2 = NumbaConvBlock(in_channels=64, out_channels=128, pooling=True)\n        \n        self.residual1 = nn.Sequential(\n            NumbaConvBlock(128, 128),\n            NumbaConvBlock(128, 128)\n        )\n\n        self.conv3 = NumbaConvBlock(in_channels=128, out_channels=256, pooling=True)\n        self.conv4 = NumbaConvBlock(in_channels=256, out_channels=512, pooling=True)\n        \n        self.residual2 = nn.Sequential(\n            NumbaConvBlock(512, 512),\n            NumbaConvBlock(512, 512)\n        )\n        \n        self.classifier = nn.Sequential(\n            NumbaMaxPool2d(4),\n            nn.Flatten(),\n            nn.Linear(in_features=512, out_features=num_classes)\n        )\n\n    def forward(self, x: Tensor):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.residual1(x) + x\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.residual2(x) + x\n        x = self.classifier(x)\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-07-09T17:46:15.183074Z","iopub.execute_input":"2024-07-09T17:46:15.183548Z","iopub.status.idle":"2024-07-09T17:46:15.193339Z","shell.execute_reply.started":"2024-07-09T17:46:15.183509Z","shell.execute_reply":"2024-07-09T17:46:15.192287Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{"execution":{"iopub.status.busy":"2024-07-09T09:07:47.346155Z","iopub.execute_input":"2024-07-09T09:07:47.346808Z","iopub.status.idle":"2024-07-09T09:07:47.351254Z","shell.execute_reply.started":"2024-07-09T09:07:47.346775Z","shell.execute_reply":"2024-07-09T09:07:47.350435Z"}}},{"cell_type":"markdown","source":"**Load dataset**","metadata":{}},{"cell_type":"code","source":"data_path = '/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)'\n\ntrain_dataset = PlantDiseaseDataset(data_path + '/train')\nval_dataset = PlantDiseaseDataset(data_path + '/valid')","metadata":{"execution":{"iopub.status.busy":"2024-07-09T17:46:15.194456Z","iopub.execute_input":"2024-07-09T17:46:15.194887Z","iopub.status.idle":"2024-07-09T17:46:27.365099Z","shell.execute_reply.started":"2024-07-09T17:46:15.194853Z","shell.execute_reply":"2024-07-09T17:46:27.364066Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Just use a subset of dataset","metadata":{}},{"cell_type":"code","source":"# train_dataset = Subset(train_dataset, torch.linspace(0, len(train_dataset), 1000).type(torch.int))\n# val_dataset = Subset(val_dataset, torch.linspace(0, len(val_dataset), 100).type(torch.int))","metadata":{"execution":{"iopub.status.busy":"2024-07-09T17:46:27.366627Z","iopub.execute_input":"2024-07-09T17:46:27.367044Z","iopub.status.idle":"2024-07-09T17:46:27.371589Z","shell.execute_reply.started":"2024-07-09T17:46:27.367008Z","shell.execute_reply":"2024-07-09T17:46:27.370497Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"**Data Loader**","metadata":{}},{"cell_type":"code","source":"batch_size = 128\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T17:46:27.372816Z","iopub.execute_input":"2024-07-09T17:46:27.373146Z","iopub.status.idle":"2024-07-09T17:46:27.381353Z","shell.execute_reply.started":"2024-07-09T17:46:27.373109Z","shell.execute_reply":"2024-07-09T17:46:27.380501Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"**Loss, Optimizer**","metadata":{"execution":{"iopub.status.busy":"2024-07-09T09:23:49.388572Z","iopub.execute_input":"2024-07-09T09:23:49.389129Z","iopub.status.idle":"2024-07-09T09:23:49.395104Z","shell.execute_reply.started":"2024-07-09T09:23:49.389096Z","shell.execute_reply":"2024-07-09T09:23:49.393962Z"}}},{"cell_type":"code","source":"model = NumbaResNet9(3, 38)\nmodel = nn.DataParallel(model, device_ids=[0, 1])\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T17:46:27.382513Z","iopub.execute_input":"2024-07-09T17:46:27.382822Z","iopub.status.idle":"2024-07-09T17:46:27.598978Z","shell.execute_reply.started":"2024-07-09T17:46:27.382797Z","shell.execute_reply":"2024-07-09T17:46:27.598045Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DataParallel(\n  (module): NumbaResNet9(\n    (conv1): NumbaConvBlock(\n      (conv): Sequential(\n        (0): NumbaConv2d()\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n      )\n    )\n    (conv2): NumbaConvBlock(\n      (conv): Sequential(\n        (0): NumbaConv2d()\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): NumbaMaxPool2d()\n      )\n    )\n    (residual1): Sequential(\n      (0): NumbaConvBlock(\n        (conv): Sequential(\n          (0): NumbaConv2d()\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n      )\n      (1): NumbaConvBlock(\n        (conv): Sequential(\n          (0): NumbaConv2d()\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n      )\n    )\n    (conv3): NumbaConvBlock(\n      (conv): Sequential(\n        (0): NumbaConv2d()\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): NumbaMaxPool2d()\n      )\n    )\n    (conv4): NumbaConvBlock(\n      (conv): Sequential(\n        (0): NumbaConv2d()\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (2): ReLU(inplace=True)\n        (3): NumbaMaxPool2d()\n      )\n    )\n    (residual2): Sequential(\n      (0): NumbaConvBlock(\n        (conv): Sequential(\n          (0): NumbaConv2d()\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n      )\n      (1): NumbaConvBlock(\n        (conv): Sequential(\n          (0): NumbaConv2d()\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n      )\n    )\n    (classifier): Sequential(\n      (0): NumbaMaxPool2d()\n      (1): Flatten(start_dim=1, end_dim=-1)\n      (2): Linear(in_features=512, out_features=38, bias=True)\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss().cuda()\n\noptimizer = optim.AdamW(params=model.parameters(), lr=1e-5)","metadata":{"execution":{"iopub.status.busy":"2024-07-09T17:46:27.600440Z","iopub.execute_input":"2024-07-09T17:46:27.600824Z","iopub.status.idle":"2024-07-09T17:46:27.606503Z","shell.execute_reply.started":"2024-07-09T17:46:27.600789Z","shell.execute_reply":"2024-07-09T17:46:27.605479Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"**Training loop**","metadata":{}},{"cell_type":"code","source":"epochs = 10","metadata":{"execution":{"iopub.status.busy":"2024-07-09T17:46:27.609992Z","iopub.execute_input":"2024-07-09T17:46:27.610305Z","iopub.status.idle":"2024-07-09T17:46:27.617484Z","shell.execute_reply.started":"2024-07-09T17:46:27.610279Z","shell.execute_reply":"2024-07-09T17:46:27.616609Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"for epoch in range(epochs):\n    running_loss = 0.0\n    \n    train_loop = tqdm(train_dataloader, desc=f'Training Epoch {epoch + 1}', leave=True)\n    for i, data in enumerate(train_loop):\n        X, y = (_.cuda() for _ in data)\n        \n        y_pred = model(X)\n        \n        loss = criterion(y_pred, y)\n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n        running_loss += loss.item()\n        \n        train_loop.set_postfix({'loss': running_loss / (i + 1)})","metadata":{"execution":{"iopub.status.busy":"2024-07-09T17:46:27.618592Z","iopub.execute_input":"2024-07-09T17:46:27.618957Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Training Epoch 1:   1%|‚ñè         | 7/550 [01:30<1:55:37, 12.78s/it, loss=5.23]","output_type":"stream"}]}]}