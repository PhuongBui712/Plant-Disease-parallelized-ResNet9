{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "055ae099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from numba import cuda\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be39eabb",
   "metadata": {},
   "source": [
    "## Define classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a970a876",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3fdd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantDiseaseDataset(Dataset):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71488ccc",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a2bbb9",
   "metadata": {},
   "source": [
    "### Numba layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb492781",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cuda.jit\n",
    "def conv2d_kernel(input, kernel, output):\n",
    "    batch_idx, out_y, out_x = cuda.grid(3)\n",
    "    if batch_idx < input.shape[0] and out_y < output.shape[2] and out_x < output.shape[3]:\n",
    "        for out_channel in range(output.shape[1]):\n",
    "            sum = 0.0\n",
    "            for in_channel in range(input.shape[1]):\n",
    "                for ky in range(kernel.shape[2]):\n",
    "                    for kx in range(kernel.shape[3]):\n",
    "                        in_y = out_y + ky\n",
    "                        in_x = out_x + kx\n",
    "                        if in_y < input.shape[2] and in_x < input.shape[3]:\n",
    "                            sum += (input[batch_idx, in_channel, in_y, in_x] *\n",
    "                                    kernel[out_channel, in_channel, ky, kx])\n",
    "            output[batch_idx, out_channel, out_y, out_x] = sum\n",
    "\n",
    "class NumbaConv2D(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size):\n",
    "        super(NumbaConv2D, self).__init__()\n",
    "        self.kernel = torch.nn.Parameter(torch.randn(out_channels, in_channels, kernel_size, kernel_size))\n",
    "        self.bias = torch.nn.Parameter(torch.zeros(out_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.is_cuda, \"Input must be a CUDA tensor\"\n",
    "        assert x.dim() == 4, \"Input must be a 4D tensor\"\n",
    "\n",
    "        # Detach input and kernel for CUDA kernel\n",
    "        x_detached = x.detach()\n",
    "        kernel_detached = self.kernel.detach()\n",
    "\n",
    "        batch_size, in_channels, in_height, in_width = x.shape\n",
    "        out_channels, _, kernel_size, _ = self.kernel.shape\n",
    "        out_height = in_height - kernel_size + 1\n",
    "        out_width = in_width - kernel_size + 1\n",
    "\n",
    "        output = torch.zeros(batch_size, out_channels, out_height, out_width, device=x.device)\n",
    "\n",
    "        threads_per_block = (8, 8, 8)\n",
    "        blocks_per_grid = (\n",
    "            math.ceil(batch_size / threads_per_block[0]),\n",
    "            math.ceil(out_height / threads_per_block[1]),\n",
    "            math.ceil(out_width / threads_per_block[2])\n",
    "        )\n",
    "\n",
    "        conv2d_kernel[blocks_per_grid, threads_per_block](\n",
    "            x_detached, kernel_detached, output\n",
    "        )\n",
    "\n",
    "        # Instead of modifying output in-place, create a new tensor\n",
    "        return output + self.bias.view(1, -1, 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d6e35ae",
   "metadata": {},
   "source": [
    "### ResNet9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd8e44ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel: Optional[int] = 3,\n",
    "                 stride: Optional[int] = 1,\n",
    "                 padding: Optional[int] = 1,\n",
    "                 pooling: Optional[bool] = False,\n",
    "                 pooling_kernel: Optional[int] = 4) -> None:\n",
    "    \n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel, stride=stride, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        if pooling:\n",
    "            self.conv.append(nn.MaxPool2d(kernel_size=pooling_kernel))\n",
    "\n",
    "    def forward(self, X: Tensor):\n",
    "        return self.conv(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e360241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet9(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 num_classes: int,) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = ConvBlock(in_channels=in_channels, out_channels=64)\n",
    "        self.conv2 = ConvBlock(in_channels=64, out_channels=128, pooling=True)\n",
    "\n",
    "        self.residual1 = nn.Sequential(\n",
    "            ConvBlock(128, 128),\n",
    "            ConvBlock(128, 128)\n",
    "        )\n",
    "\n",
    "        self.conv3 = ConvBlock(in_channels=128, out_channels=256, pooling=True)\n",
    "        self.conv4 = ConvBlock(in_channels=256, out_channels=512, pooling=True)\n",
    "\n",
    "        self.residual2 = nn.Sequential(\n",
    "            ConvBlock(512, 512),\n",
    "            ConvBlock(512, 512)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.MaxPool2d(4),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=512, out_features=num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: Tensor):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.residual1(x) + x\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.residual2(x) + x\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a5d648",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cab3b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
